{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0221ENSkillsNetwork23455645-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extract Transform Load (ETL) Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "*   Read CSV and JSON file types.\n",
    "*   Extract data from the above file types.\n",
    "*   Transform data.\n",
    "*   Save the transformed data in a ready-to-load format which data engineers can use to load into an RDBMS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required modules and functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob                         # this module helps in selecting files \n",
    "import pandas as pd                 # this module helps in processing CSV files\n",
    "import xml.etree.ElementTree as ET  # this module helps in processing XML files.\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: wget: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open source.zip, source.zip.zip or source.zip.ZIP.\r\n"
     ]
    }
   ],
   "source": [
    "!unzip source.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfile    = \"temp.tmp\"               # file used to store all extracted data\n",
    "logfile    = \"logfile.txt\"            # all event logs will be stored in this file\n",
    "targetfile = \"transformed_data.csv\"   # file where transformed data is stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv(file_to_process):\n",
    "    dataframe = pd.read_csv(file_to_process)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_json(file_to_process):\n",
    "    dataframe = pd.read_json(file_to_process,lines=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_xml(file_to_process):\n",
    "    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"])\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "    for person in root:\n",
    "        name = person.find(\"name\").text\n",
    "        height = float(person.find(\"height\").text)\n",
    "        weight = float(person.find(\"weight\").text)\n",
    "        dataframe = dataframe.append({\"name\":name, \"height\":height, \"weight\":weight}, ignore_index=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data\n",
    "    \n",
    "    #process all csv files\n",
    "    for csvfile in glob.glob(\"*.csv\"):\n",
    "        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
    "        \n",
    "    #process all json files\n",
    "    for jsonfile in glob.glob(\"*.json\"):\n",
    "        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n",
    "    \n",
    "    #process all xml files\n",
    "    for xmlfile in glob.glob(\"*.xml\"):\n",
    "        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n",
    "        \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transform function does the following tasks.\n",
    "\n",
    "1.  Convert height which is in inches to millimeter\n",
    "2.  Convert weight which is in pounds to kilograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "        #Convert height which is in inches to millimeter\n",
    "        #Convert the datatype of the column into float\n",
    "        #data.height = data.height.astype(float)\n",
    "        #Convert inches to meters and round off to two decimals(one inch is 0.0254 meters)\n",
    "        data['height'] = round(data.height * 0.0254,2)\n",
    "        \n",
    "        #Convert weight which is in pounds to kilograms\n",
    "        #Convert the datatype of the column into float\n",
    "        #data.weight = data.weight.astype(float)\n",
    "        #Convert pounds to kilograms and round off to two decimals(one pound is 0.45359237 kilograms)\n",
    "        data['weight'] = round(data.weight * 0.45359237,2)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(targetfile,data_to_load):\n",
    "    data_to_load.to_csv(targetfile)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(message):\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second\n",
    "    now = datetime.now() # get current timestamp\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(\"logfile.txt\",\"a\") as f:\n",
    "        f.write(timestamp + ',' + message + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running ETL Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"ETL Job Started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, height, weight]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log(\"Extract phase Started\")\n",
    "extracted_data = extract()\n",
    "log(\"Extract phase Ended\")\n",
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, height, weight]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log(\"Transform phase Started\")\n",
    "transformed_data = transform(extracted_data)\n",
    "log(\"Transform phase Ended\")\n",
    "transformed_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"Load phase Started\")\n",
    "load(targetfile,transformed_data)\n",
    "log(\"Load phase Ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log(\"ETL Job Ended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the example above complete the exercise below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/portable-ruby/portable-ruby/blobs/sha256:1f50bf80583bd436c9542d4fa5ad47df0ef0f0bea22ae710c4f04c42d7560bca\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring portable-ruby-2.6.8_1.el_capitan.bottle.tar.gz\u001b[0m\n",
      "\u001b[33mWarning:\u001b[0m You are using macOS 10.15.\n",
      "We (and Apple) do not provide support for this old version.\n",
      "It is expected behaviour that some formulae will fail to build in this old version.\n",
      "It is expected behaviour that Homebrew will be buggy and slow.\n",
      "Do not create any issues about this on Homebrew's GitHub repositories.\n",
      "Do not create any issues even if you think this message is unrelated.\n",
      "Any opened issues will be immediately closed without response.\n",
      "Do not ask for help from MacHomebrew on Twitter.\n",
      "You may ask for help in Homebrew's discussions but are unlikely to receive a response.\n",
      "Try to figure out the problem yourself and submit a fix as a pull request.\n",
      "We will review it but may or may not accept it.\n",
      "\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching dependencies for wget: \u001b[32mlibunistring\u001b[39m, \u001b[32mlibidn2\u001b[39m and \u001b[32mopenssl@1.1\u001b[39m\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibunistring\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libunistring/manifests/0.9.10\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libunistring/blobs/sha256:ce746\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mlibidn2\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libidn2/manifests/2.3.2\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/libidn2/blobs/sha256:71c5f183ae\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mopenssl@1.1\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/openssl/1.1/manifests/1.1.1l\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/openssl/1.1/blobs/sha256:9c8490\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mwget\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/wget/manifests/1.21.2\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/wget/blobs/sha256:3b191bb28b501\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling dependencies for wget: \u001b[32mlibunistring\u001b[39m, \u001b[32mlibidn2\u001b[39m and \u001b[32mopenssl@1.1\u001b[39m\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling wget dependency: \u001b[32mlibunistring\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libunistring--0.9.10.catalina.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /usr/local/Cellar/libunistring/0.9.10: 54 files, 4.4MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling wget dependency: \u001b[32mlibidn2\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring libidn2--2.3.2.catalina.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /usr/local/Cellar/libidn2/2.3.2: 77 files, 846.5KB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling wget dependency: \u001b[32mopenssl@1.1\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring openssl@1.1--1.1.1l.catalina.bottle.tar.gz\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRegenerating CA certificate bundle from keychain, this may take a while...\u001b[0m\n",
      "ðŸº  /usr/local/Cellar/openssl@1.1/1.1.1l: 8,073 files, 18.5MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling \u001b[32mwget\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring wget--1.21.2.catalina.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /usr/local/Cellar/wget/1.21.2: 89 files, 4.2MB\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRunning `brew cleanup wget`...\u001b[0m\n",
      "Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.\n",
      "Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n"
     ]
    }
   ],
   "source": [
    "!brew install wget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-17 14:06:25--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip\n",
      "Resolviendo cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
      "Conectando con cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)[169.63.118.104]:443... conectado.\n",
      "PeticiÃ³n HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 4249 (4.1K) [application/zip]\n",
      "Grabando a: Â«datasource.zipÂ»\n",
      "\n",
      "datasource.zip      100%[===================>]   4.15K  --.-KB/s    en 0s      \n",
      "\n",
      "2023-01-17 14:06:26 (225 MB/s) - Â«datasource.zipÂ» guardado [4249/4249]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  datasource.zip\r\n",
      "  inflating: dealership_data/used_car_prices1.csv  \r\n",
      "  inflating: dealership_data/used_car_prices2.csv  \r\n",
      "  inflating: dealership_data/used_car_prices3.csv  \r\n",
      "  inflating: dealership_data/used_car_prices1.json  \r\n",
      "  inflating: dealership_data/used_car_prices2.json  \r\n",
      "  inflating: dealership_data/used_car_prices3.json  \r\n",
      "  inflating: dealership_data/used_car_prices1.xml  \r\n",
      "  inflating: dealership_data/used_car_prices2.xml  \r\n",
      "  inflating: dealership_data/used_car_prices3.xml  \r\n"
     ]
    }
   ],
   "source": [
    "!unzip datasource.zip -d dealership_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `dealership_data` contains CSV, JSON, and XML files for used car data which contain features named `car_model`, `year_of_manufacture`, `price`, and `fuel`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfile    = \"dealership_temp.tmp\"               # file used to store all extracted data\n",
    "logfile    = \"dealership_logfile.txt\"            # all event logs will be stored in this file\n",
    "targetfile = \"dealership_transformed_data.csv\"   # file where transformed data is stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: CSV Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the CSV extract function below\n",
    "def extractCSV(file):\n",
    "    df = pd.read_csv(file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```\n",
    "    \n",
    "def extract_from_csv(file_to_process):\n",
    "    dataframe = pd.read_csv(file_to_process)\n",
    "    return dataframe\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: JSON Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the JSON extract function below\n",
    "import json\n",
    "def extractJSON(file):\n",
    "    df = pd.read_json(file, lines=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```\n",
    "    \n",
    "def extract_from_json(file_to_process):\n",
    "    dataframe = pd.read_json(file_to_process,lines=True)\n",
    "    return dataframe\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: XML Extract Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the XML extract function below, it is the same as the xml extract function above but the column names need to be renamed.\n",
    "import xml.etree.ElementTree as ET  # this module helps in processing XML files.\n",
    "\n",
    "def extractXML(file):\n",
    "    df = pd.DataFrame(columns=[\"car_model\", \"year_of_manufacture\",\"price\", \"fuel\"])\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "    for car in root:\n",
    "        model = car.find(\"car_model\").text\n",
    "        year = int(car.find(\"year_of_manufacture\").text)\n",
    "        price = float(car.find(\"price\").text)\n",
    "        fuel = car.find(\"fuel\").text\n",
    "        df = df.append({\"car_model\":model, \"year_of_manufacture\":year,\"price\":price, \"fuel\":fuel}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```\n",
    "    \n",
    "def extract_from_xml(file_to_process):\n",
    "    dataframe = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel'])\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "    for person in root:\n",
    "        car_model = person.find(\"car_model\").text\n",
    "        year_of_manufacture = int(person.find(\"year_of_manufacture\").text)\n",
    "        price = float(person.find(\"price\").text)\n",
    "        fuel = person.find(\"fuel\").text\n",
    "        dataframe = dataframe.append({\"car_model\":car_model, \"year_of_manufacture\":year_of_manufacture, \"price\":price, \"fuel\":fuel}, ignore_index=True)\n",
    "    return dataframe\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Extract Function\n",
    "\n",
    "Call the specific extract functions you created above by replacing the `ADD_FUNCTION_CALL` with the proper function call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n",
    "    \n",
    "    #process all csv files\n",
    "    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n",
    "        extracted_data = extracted_data.append(extractCSV(csvfile), ignore_index=True)\n",
    "        \n",
    "    #process all json files\n",
    "    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n",
    "        extracted_data = extracted_data.append(extractJSON(jsonfile), ignore_index=True)\n",
    "    \n",
    "    #process all xml files\n",
    "    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n",
    "        extracted_data = extracted_data.append(extractXML(xmlfile), ignore_index=True)\n",
    "        \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_model</th>\n",
       "      <th>year_of_manufacture</th>\n",
       "      <th>price</th>\n",
       "      <th>fuel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ritz</td>\n",
       "      <td>2014</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sx4</td>\n",
       "      <td>2013</td>\n",
       "      <td>7089.552239</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ciaz</td>\n",
       "      <td>2017</td>\n",
       "      <td>10820.895522</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wagon r</td>\n",
       "      <td>2011</td>\n",
       "      <td>4253.731343</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>swift</td>\n",
       "      <td>2014</td>\n",
       "      <td>6865.671642</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>etios liva</td>\n",
       "      <td>2014</td>\n",
       "      <td>7089.552239</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>innova</td>\n",
       "      <td>2017</td>\n",
       "      <td>29477.611940</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>fortuner</td>\n",
       "      <td>2010</td>\n",
       "      <td>13805.970149</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>corolla altis</td>\n",
       "      <td>2011</td>\n",
       "      <td>6492.537313</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>corolla altis</td>\n",
       "      <td>2016</td>\n",
       "      <td>21268.656716</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        car_model year_of_manufacture         price    fuel\n",
       "0            ritz                2014   5000.000000  Petrol\n",
       "1             sx4                2013   7089.552239  Diesel\n",
       "2            ciaz                2017  10820.895522  Petrol\n",
       "3         wagon r                2011   4253.731343  Petrol\n",
       "4           swift                2014   6865.671642  Diesel\n",
       "..            ...                 ...           ...     ...\n",
       "85     etios liva                2014   7089.552239  Diesel\n",
       "86         innova                2017  29477.611940  Petrol\n",
       "87       fortuner                2010  13805.970149  Diesel\n",
       "88  corolla altis                2011   6492.537313  Petrol\n",
       "89  corolla altis                2016  21268.656716  Petrol\n",
       "\n",
       "[90 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataCars = extract()\n",
    "dataCars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```\n",
    "    \n",
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price', 'fuel']) # create an empty data frame to hold extracted data\n",
    "    \n",
    "    #process all csv files\n",
    "    for csvfile in glob.glob(\"dealership_data/*.csv\"):\n",
    "        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
    "        \n",
    "    #process all json files\n",
    "    for jsonfile in glob.glob(\"dealership_data/*.json\"):\n",
    "        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n",
    "    \n",
    "    #process all xml files\n",
    "    for xmlfile in glob.glob(\"dealership_data/*.xml\"):\n",
    "        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n",
    "        \n",
    "    return extracted_data\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Transform\n",
    "\n",
    "Round the `price` columns to 2 decimal places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the transform function below\n",
    "def transform2(data):\n",
    "    data[\"price\"] = round(data[\"price\"],2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```\n",
    "\n",
    "def transform(data):\n",
    "        data['price'] = round(data.price, 2)\n",
    "        return data\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the load function below\n",
    "def load(targetfile, dataframe):\n",
    "    dataframe.to_csv(targetfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```\n",
    "\n",
    "def load(targetfile,data_to_load):\n",
    "    data_to_load.to_csv(targetfile)  \n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Log\n",
    "\n",
    "Make sure to change the name of the logfile to the one specified in the set paths section. Change the timestamp order to Hour-Minute-Second-Monthname-Day-Year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the log function below\n",
    "def log(message):\n",
    "    timestamp_format = '%H:%M:%S-%h-%d-%Y' #Hour-Minute-Second-MonthName-Day-Year\n",
    "    now = datetime.now() # get current timestamp\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(\"dealership_logfile.txt\",\"a\") as f:\n",
    "        f.write(timestamp + ',' + message + '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```\n",
    "\n",
    "def log(message):\n",
    "    timestamp_format = '%H:%M:%S-%h-%d-%Y' #Hour-Minute-Second-MonthName-Day-Year\n",
    "    now = datetime.now() # get current timestamp\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(\"dealership_logfile.txt\",\"a\") as f:\n",
    "        f.write(timestamp + ',' + message + '\\n') \n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running ETL Process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: ETL Process\n",
    "\n",
    "Run all functions to extract, transform, and load the data. Make sure to log all events using the `log` function. Place your code under each comment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log that you have started the ETL process\n",
    "\n",
    "log(\"started ETL process\")\n",
    "# Log that you have started the Extract step\n",
    "log(\"started Extract process\")\n",
    "# Call the Extract function\n",
    "dataCars = extract()\n",
    "\n",
    "# Log that you have completed the Extract step\n",
    "log(\"finished Extract process\")\n",
    "\n",
    "\n",
    "# Log that you have started the Transform step\n",
    "log(\"started transform process\")\n",
    "dataCars = transform2(dataCars)\n",
    "# Call the Transform function\n",
    "\n",
    "# Log that you have completed the Transform step\n",
    "log(\"finished transform process\")\n",
    "\n",
    "\n",
    "# Log that you have started the Load step\n",
    "log(\"started load process\")\n",
    "# Call the Load function\n",
    "load(\"unificado.csv\", dataCars)\n",
    "# Log that you have completed the Load step\n",
    "log(\"finished load process\")\n",
    "\n",
    "\n",
    "# Log that you have completed the ETL process\n",
    "log(\"finished ETL process\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for the solution</summary>\n",
    "\n",
    "```\n",
    "\n",
    "log(\"ETL Job Started\")\n",
    "\n",
    "log(\"Extract phase Started\")\n",
    "extracted_data = extract()\n",
    "log(\"Extract phase Ended\")\n",
    "\n",
    "log(\"Transform phase Started\")\n",
    "transformed_data = transform(extracted_data)\n",
    "log(\"Transform phase Ended\")\n",
    "\n",
    "log(\"Load phase Started\")\n",
    "load(targetfile,transformed_data)\n",
    "log(\"Load phase Ended\")\n",
    "\n",
    "log(\"ETL Job Ended\")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramesh Sannareddy\n",
    "\n",
    "Joseph Santarcangelo\n",
    "\n",
    "Azim Hirjani\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n",
    "| ----------------- | ------- | ----------------- | ---------------------------------- |\n",
    "| 2020-11-25        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright Â© 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0221ENSkillsNetwork23455645-2022-01-01&cm_mmc=Email_Newsletter-\\_-Developer_Ed%2BTech-\\_-WW_WW-\\_-SkillsNetwork-Courses-IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork-23455645&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
